---
title: 'Practical II  (solutions)'
subtitle: Bennett Kleinberg
date: 'Statistical Natural Language Processing in R'
output:
  html_document:
    toc: yes
    df_print: paged
    code_folding: show
  html_notebook:
    theme: united
    toc: yes
    code_folding: show
  pdf_document:
    toc: yes
    code_folding: show
---

## Aims of this practical

- Working with DFM objects
- Dimensionality reduction of text representations
- Using text representations for similarity calculations

## Task 1: Text representations as document-feature matrices

Load the [YouTube vlogs dataset](https://aclanthology.org/D18-1394.pdf) from Practical I. We will now work with the first kind of text representations: document-feature matrices.

```{r}
library(quanteda)
library(data.table)
load('/Users/bennettkleinberg/GitHub/snlp/data/vlogs_corpus.RData')
```

### Exercise 1.1

Built a simple term frequency matrix. Compare the dimensions after each of these preprocessing steps successively:

1. raw (without any preprocessing)
1. after lower-casing
1. after removing punctuation
1. after removing stopwords
1. after including only terms which occur in at least 1% of the documents


Depending on the memory on your machine, running the whole dataset might slow you down. In that case, you can also choose to only use a subs election of the dataset (e.g., the first 5000 vlogs).

```{r}
# create a corpus object
c_vlogs = corpus(vlogs_corpus$text[1:5000])

# tokenise the data
toks_vlogs = quanteda::tokens(c_vlogs)


# create a dfm
dfm_vlogs = dfm(tokens_ngrams(toks_vlogs
                                 , n = 1)
                   , tolower = F)
dfm_vlogs

# apply lower-casing
dfm_vlogs_1 = dfm(tokens_ngrams(toks_vlogs
                                 , n = 1)
                   , tolower = T)
dfm_vlogs_1

# remove punctuation
toks_vlogs_no_punct = tokens_select(toks_vlogs
                                    , pattern = "[[:punct:]]"
                                    , valuetype = "regex"
                                    , selection = 'remove')

dfm_vlogs_2 = dfm(tokens_ngrams(toks_vlogs_no_punct
                                 , n = 1)
                   , tolower = T)
dfm_vlogs_2


# remove stopwords
toks_vlogs_no_stopw = tokens_select(toks_vlogs_no_punct
                                    , pattern = stopwords('en')
                                    , selection = 'remove')

dfm_vlogs_3 = dfm(tokens_ngrams(toks_vlogs_no_stopw
                                 , n = 1)
                   , tolower = T)
dfm_vlogs_3

# sparsity correction
dfm_vlogs_4 = dfm_trim(dfm_vlogs_3
                , min_docfreq = 0.01
                , docfreq_type = 'prop')
dfm_vlogs_4
```


### Exercise 1.2

Now move to n-gram representations. Built a representation of uni-, bi-, and trigrams.
How does the sparsity of your DFM representation change if you apply stemming?

```{r}
# assuming the same preprocessing steps from Exercise 1.1
## Note: the sparsity correction through "dfm trimming" makes sense only after stemming

dfm_ngrams = dfm(tokens_ngrams(toks_vlogs_no_stopw
                                 , n = 1:3)
                   , tolower = T)

dfm_ngrams


dfm_ngrams_stemmed = dfm_wordstem(x = dfm_ngrams)
dfm_ngrams_stemmed


```


### Exercise 1.3

Apply a weighting to the n-gram representation. Then compare the most important terms before and after applying a weighting such as TF-IDF.

```{r}
# here we can also apply a sparsity correction (here: 5%)
dfm_vlogs = dfm_trim(dfm_ngrams_stemmed
                , min_docfreq = 0.05
                , docfreq_type = 'prop')


dfm_weighted = dfm_tfidf(dfm_vlogs
                      , scheme_tf = "count"
                      , scheme_df = "inverse")

dfm_weighted

# we can retrieve the most important terms with the topfeatures function
topfeatures(dfm_vlogs)
topfeatures(dfm_weighted)
```

## Task 2: Working with text representations

For this task, we will use the [Hippocorpus dataset](https://aclanthology.org/2020.acl-main.178.pdf). From the dataset summary:

> To examine the cognitive processes of remembering and imagining and their traces in language, we introduce Hippocorpus, a dataset of 6,854 English diary-like short stories about recalled and imagined events. Using a crowdsourcing framework, we first collect recalled stories and summaries from workers, then provide these summaries to other workers who write imagined stories. Finally, months later, we collect a retold version of the recalled stories from a subset of recalled authors. Our dataset comes paired with author demographics (age, gender, race), their openness to experience, as well as some variables regarding the author's relationship to the event (e.g., how personal the event is, how often they tell its story, etc.).

You can obtain the dataset from publicly available repos or via the `data` directory as follows:

```{r}
hc = fread('/Users/bennettkleinberg/GitHub/snlp/data/hippocorpus_preprocessed.csv')
names(hc)

# note that we only use the remembered statements (=truthful) and the fabricated ones (=deceptive).
```

### Exercise 2.1

Build an n-gram representation of the data with preprocessing steps of your choice (think about whether these are useful or not). Stem the terms and apply a 5% document frequency minimum.

```{r}
# corpus
hc_corpus = corpus(hc$text
                   , docvars = hc[, c(1, 3)])

# tokenise
hc_toks = quanteda::tokens(hc_corpus
                           , remove_punct = T
                           , include_docvars = T)

# dfm
hc_dfm = dfm(tokens_ngrams(hc_toks
                           , n = 1:3)
             , tolower = T)

# stemming
hc_dfm_stemmed = dfm_wordstem(x = hc_dfm)

# sparsity correction
hc_dfm_red = dfm_trim(hc_dfm_stemmed
                      , min_docfreq = 0.05
                      , docfreq_type = 'prop')

hc_dfm_red

```


### Exercise 2.2

What are the most important terms for truthful vs deceptive stories? You can use your DFM from above. Have a look at the `topfeatures()` function for a quick way of looking at these terms. 

_Hint: You will first need to assign a document-level variable. This can be done in the very first steps (i.e., when creating a corpus and then handing the docvars over to the tokens)._

```{r}
# overall topfeatures
topfeatures(hc_dfm_red)

# group by condition
topfeatures(hc_dfm_red, groups = condition)
```


### Exercise 2.3

We can now take one step closer to working with textual data to understand psychological and cognitive aspects. The Hippocorpus dataset allows us to measure how much participants relied on the given summary. That, in turn, can be used for further analyses to look at individual differences (e.g., is that reliance on the summary - or conversely, deviance from it, related to age differences?) and group differences (e.g., does this differ between truthful and deceptive narratives?). We will take a look at the latter in Exercise 2.4.

Compare the cosine similarity - based on an n-gram representation - of the stories with the provided summaries (columns: `text` and `summary`). Each text has got a summary and your goal is to quantify the similarity between text and summary.

Hints:

- you will need to create DFM representations for texts and for the summaries
- a problem you will encounter is that these do not necessarily result in the same ngrams
- this can be fixed with the `dfm_match()` function

For the cosine similarity, you can use the snippet below:

```{r}
# for two vectors A and B, returns the cosine similarity between A and B
cossim = function(A, B){
  numerator = sum(A*B)
  denominator = sqrt(sum(A*A))*sqrt(sum(B*B))
  cosine_sim = numerator/denominator
  return(cosine_sim)
}
```



```{r}
# create DFM for texts
## corpus
hc_corpus = corpus(hc$text
                   , docvars = hc[, c(1, 3)])

## tokenise
hc_toks = quanteda::tokens(hc_corpus
                           , remove_punct = T
                           , include_docvars = T)

## dfm
hc_dfm_text = dfm(tokens_ngrams(hc_toks
                           , n = 1:3)
             , tolower = T)

# sparsity correction
hc_dfm_red_text = dfm_trim(hc_dfm_text
                           , min_docfreq = 0.05
                           , docfreq_type = 'prop')

# create DFM for texts (trimming not needed here since we match the dfms)
## corpus
hc_corpus = corpus(hc$summary
                   , docvars = hc[, c(1, 3)])

## tokenise
hc_toks = quanteda::tokens(hc_corpus
                           , remove_punct = T
                           , include_docvars = T)

## dfm
hc_dfm_summary = dfm(tokens_ngrams(hc_toks
                           , n = 1:3)
             , tolower = T)


# now we match the DFMs: we want the larger dfm (summaries) to only contain the ngrams from the reduced dfm (texts)
hc_dfm_summary_match = dfm_match(hc_dfm_summary
                                 , featnames(hc_dfm_red_text))

# Now both DFMs (i.e., hc_dfm_red_text and hc_dfm_summary_match) contain the same variables.
# We can then use a loop to calculate the cosine similarities:
## To achieve this, we first convert the relevant DFMs to data.frames

dfm_hc_text = convert(hc_dfm_red_text, to='data.frame')
dfm_hc_summary = convert(hc_dfm_summary_match, to='data.frame')

## Confirm that the names are equal
names(dfm_hc_summary)
names(dfm_hc_text)

## The first variable is the document id, we need to ignore this one for the cosine similarity

### set a variable to populate in the loop
dfm_hc_text$cosine_sim = 0

for(i in 1:nrow(dfm_hc_text)){
  
  print(paste0('Processing: ', i, '/', nrow(dfm_hc_text)))
  
  vec_a = dfm_hc_text[i, 2:849]
  vec_b = dfm_hc_summary[i, 2:849]
  
  cosine_sim = cossim(vec_a, vec_b)
  
  dfm_hc_text$cosine_sim[i] = cosine_sim
  
}

## The cosine similarities are now in the dfm_hc_text data.frame
head(dfm_hc_text$cosine_sim)
```


### Exercise 2.4

What is the effect size (Cohen's d) of the difference in cosine similarity of text and summary between truthful and deceptive texts?

```{r warning=F}
# Add back the docvar indicating the condition
dfm_hc_text$CONDITION = hc_dfm_red_text$condition

## Note: the full uppercase notation can be useful to differentiate these docvars in a data.frame/data.table from a feature (ngram) that may be called "condition".
## Note: quanteda maintains the order in the data and will not shuffle texts, so you can add variables back in (with other R packages/functions this is riskier!)

# convert to data.table (optional)
dt_dfm_hc_text = setDT(dfm_hc_text)

# obtain descriptives (here we directly exclude the case without a condition)
dt_dfm_hc_text[CONDITION != "", .('M' = mean(cosine_sim, na.rm = T)
                                  , 'SD' = sd(cosine_sim, na.rm = T))
               , by = .(CONDITION)]

# calculate effect size d
library(effectsize)
cohens_d(data = dt_dfm_hc_text[CONDITION != "", ]
         , cosine_sim ~ CONDITION, ci = .95)

```


